{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "import copy\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.__version__\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "read_path = '../../Qilin'\n",
    "save_path = '..'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_features = pd.read_pickle(f'{read_path}/raw_data/item_feat_encoded.pkl')\n",
    "item_features.head(1)\n",
    "item_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_features['image_path'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_null(row):\n",
    "    row_text = row['text'].strip()\n",
    "    return len(row_text)==0\n",
    "\n",
    "text_null_data = item_features.apply(text_null,axis=1)\n",
    "text_null_data.sum()\n",
    "\n",
    "item_features = item_features[~text_null_data].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter = pd.read_pickle(f\"{read_path}/raw_data/rec_inter.pkl\")\n",
    "rec_inter = rec_inter.sort_values(by=['user_id','timestamp']).reset_index(drop=True)\n",
    "rec_inter.head()\n",
    "rec_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_user_item = rec_inter[['user_id','item_id']]\n",
    "all_user_item.head(1)\n",
    "all_user_item.shape\n",
    "\n",
    "all_user_item['user_id'].value_counts()\n",
    "all_user_item['item_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remain_user_item = all_user_item.copy()\n",
    "filter_num=3\n",
    "while (remain_user_item['user_id'].value_counts() < filter_num).sum() > 0:\n",
    "    print(\"filter user\")\n",
    "    remain_user_cnt = remain_user_item['user_id'].value_counts()\n",
    "    remained_user = remain_user_cnt[remain_user_cnt>=filter_num].index.to_list()\n",
    "    remain_user_item = remain_user_item[remain_user_item['user_id'].isin(remained_user)]\n",
    "\n",
    "    while (remain_user_item['item_id'].value_counts() < filter_num).sum() > 0:\n",
    "        print(\"filter item\")\n",
    "        remain_item_cnt = remain_user_item['item_id'].value_counts()\n",
    "        remained_item = remain_item_cnt[remain_item_cnt>=filter_num].index.to_list()\n",
    "        remain_user_item = remain_user_item[remain_user_item['item_id'].isin(remained_item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remain_user_item['user_id'].value_counts()\n",
    "remain_user_item['item_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rec_inter[(rec_inter['user_id'].isin(remain_user_item['user_id'].unique())) &\n",
    "          (rec_inter['item_id'].isin(remain_user_item['item_id'].unique()))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Src data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter = pd.read_pickle(f\"{read_path}/raw_data/src_inter_encoded.pkl\")\n",
    "src_inter = src_inter.sort_values(by=['user_id','timestamp']).reset_index(drop=True)\n",
    "src_inter.head()\n",
    "src_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = pd.read_pickle(f'{read_path}/raw_data/user_feat.pkl')\n",
    "user_features.head(1)\n",
    "user_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map user/item to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter = rec_inter[rec_inter['item_id'].isin(item_features['item_id'].unique())].reset_index(drop=True)\n",
    "rec_inter = rec_inter[rec_inter['user_id'].isin(user_features['user_id'].unique())].reset_index(drop=True)\n",
    "rec_inter.shape\n",
    "\n",
    "src_inter = src_inter[src_inter['item_id'].isin(item_features['item_id'].unique())].reset_index(drop=True)\n",
    "src_inter = src_inter[src_inter['user_id'].isin(user_features['user_id'].unique())].reset_index(drop=True)\n",
    "src_inter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_user_set = set(rec_inter['user_id'].unique())\n",
    "src_user_set = set(src_inter['user_id'].unique())\n",
    "\n",
    "len(rec_user_set)\n",
    "len(src_user_set)\n",
    "len(rec_user_set | src_user_set)\n",
    "len(rec_user_set & src_user_set)\n",
    "\n",
    "all_user_set = list(rec_user_set | src_user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rec_user_set - src_user_set)\n",
    "len(src_user_set - rec_user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter = rec_inter[rec_inter['user_id'].isin(all_user_set)].reset_index(drop=True)\n",
    "rec_inter.shape\n",
    "\n",
    "src_inter = src_inter[src_inter['user_id'].isin(all_user_set)].reset_index(drop=True)\n",
    "src_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rec_inter['user_id'].value_counts() >= 5).sum() / rec_inter['user_id'].nunique()\n",
    "\n",
    "(rec_inter['user_id'].value_counts() >= 10).sum() / rec_inter['user_id'].nunique()\n",
    "\n",
    "(rec_inter['user_id'].value_counts() >= 20).sum() / rec_inter['user_id'].nunique()\n",
    "\n",
    "(rec_inter['user_id'].value_counts() >= 30).sum() / rec_inter['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(src_inter['user_id'].value_counts() >= 5).sum() / src_inter['user_id'].nunique()\n",
    "\n",
    "(src_inter['user_id'].value_counts() >= 10).sum() / src_inter['user_id'].nunique()\n",
    "\n",
    "(src_inter['user_id'].value_counts() >= 20).sum() / src_inter['user_id'].nunique()\n",
    "\n",
    "(src_inter['user_id'].value_counts() >= 30).sum() / src_inter['user_id'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rec_inter_dict = rec_inter['user_id'].value_counts().to_dict()\n",
    "len(num_rec_inter_dict)\n",
    "\n",
    "num_src_inter_dict = src_inter['user_id'].value_counts().to_dict()\n",
    "len(num_src_inter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = user_features.rename(columns={'user_id':'user'})\n",
    "\n",
    "user_features['num_rec_inter'] = user_features['user'].map(lambda x: num_rec_inter_dict.get(x,0))\n",
    "user_features['num_src_inter'] = user_features['user'].map(lambda x: num_src_inter_dict.get(x,0))\n",
    "\n",
    "user_features = user_features.astype({\"user\":'category'})\n",
    "id2user = user_features['user'].cat.categories.to_list()\n",
    "\n",
    "user2id = {id2user[k]:k for k in range(len(id2user))} \n",
    "\n",
    "user_features['user_id'] = user_features['user'].map(user2id)\n",
    "\n",
    "user_features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_item_set = set(rec_inter['item_id'].unique())\n",
    "src_item_set = set(src_inter['item_id'].unique())\n",
    "\n",
    "len(rec_item_set)\n",
    "len(src_item_set)\n",
    "len(rec_item_set | src_item_set)\n",
    "len(rec_item_set & src_item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = item_features[item_features['item_id'].isin(rec_item_set | src_item_set)].reset_index(drop=True)\n",
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = item_features.rename(columns={'item_id':'item'})\n",
    "item_features = item_features.astype({\"item\":'category'})\n",
    "id2item = item_features['item'].cat.categories.to_list()\n",
    "# id2item[0]\n",
    "item2id = {id2item[k]:k+1 for k in range(len(id2item))} # +1 for padding\n",
    "# item2id[0]\n",
    "item_features['item_id'] = item_features['item'].map(item2id)\n",
    "\n",
    "item_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_item_df = pd.DataFrame({\"item_id\": [0],})\n",
    "pad_item_df\n",
    "\n",
    "all_item_df = pd.concat([pad_item_df, item_features],axis=0)\n",
    "all_item_df['item_id'] = all_item_df['item_id'].astype('int')\n",
    "all_item_df = all_item_df.sort_values(by=['item_id']).reset_index(drop=True)\n",
    "\n",
    "all_item_df['item_id'].nunique()\n",
    "all_item_df.head()\n",
    "all_item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vocab = all_item_df.set_index('item_id',drop=False).to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter['user_id'] = rec_inter['user_id'].apply(lambda x:user2id[int(x)])\n",
    "rec_inter['item_id'] = rec_inter['item_id'].apply(lambda x:item2id[int(x)])\n",
    "rec_inter.head()\n",
    "rec_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter['user_id'] = src_inter['user_id'].apply(lambda x:user2id[int(x)])\n",
    "src_inter['item_id'] = src_inter['item_id'].apply(lambda x:item2id[int(x)])\n",
    "src_inter.head()\n",
    "src_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter['keyword'] = src_inter['keyword'].astype('str')\n",
    "session_src_inter = src_inter.groupby(by=['user_id','search_session_id','query','query_id','keyword']).agg(\n",
    "    click_list=('click',list),\n",
    "    pos_items=(\"item_id\",list),\n",
    "    time_list=('timestamp',list)\n",
    ").reset_index()\n",
    "session_src_inter = session_src_inter.sort_values(by=['user_id']).reset_index(drop=True)\n",
    "session_src_inter.head()\n",
    "session_src_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_src_inter = session_src_inter.drop_duplicates(subset=['user_id','search_session_id'], keep='first').reset_index(drop=True)\n",
    "session_src_inter.shape\n",
    "session_src_inter['search_session_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_src_inter['search_session_id'] = session_src_inter['search_session_id'].astype('category')\n",
    "\n",
    "id2session = session_src_inter['search_session_id'].cat.categories.to_list()\n",
    "session2id = {id2session[k]:k+1 for k in range(len(id2session))}\n",
    "\n",
    "session_src_inter['search_session_id'] = session_src_inter['search_session_id'].apply(lambda x:session2id[x])\n",
    "# +1 for padding\n",
    "session_src_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter['search_session_id'] = src_inter['search_session_id'].map(session2id)\n",
    "src_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_src_inter['keyword'] = session_src_inter['keyword'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_vocab = session_src_inter[['search_session_id', 'query', 'query_id', 'keyword',\n",
    "                                   'pos_items','click_list','time_list']].set_index('search_session_id',drop=False).to_dict('index')\n",
    "session_vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_time(row):\n",
    "    return row['time_list'][0]\n",
    "\n",
    "session_src_inter['timestamp'] = session_src_inter.apply(get_session_time,axis=1)\n",
    "session_src_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_rec_inter = rec_inter[['user_id','item_id','timestamp']].copy()\n",
    "sub_rec_inter['search_session_id'] = 'nan'\n",
    "sub_rec_inter['behavior'] = 1\n",
    "\n",
    "sub_session_src_inter = session_src_inter[['user_id','timestamp','search_session_id']].copy()\n",
    "sub_session_src_inter['item_id'] = 'nan'\n",
    "sub_session_src_inter['behavior'] = 2\n",
    "\n",
    "sar_inter = pd.concat([sub_rec_inter,sub_session_src_inter],axis=0)\n",
    "sar_inter = sar_inter.sort_values(by=['user_id','timestamp']).reset_index(drop=True)\n",
    "sar_inter.head()\n",
    "sar_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vocab = user_features.set_index('user_id',drop=False).to_dict('index')\n",
    "for key in user_vocab.keys():\n",
    "    user_vocab[key]['rec_his'] = []\n",
    "    user_vocab[key]['rec_his_ts'] = []\n",
    "    user_vocab[key]['src_session_his'] = []\n",
    "    user_vocab[key]['src_session_his_ts'] = []\n",
    "    user_vocab[key]['src_his'] = []\n",
    "    user_vocab[key]['src_his_ts'] = []\n",
    "    user_vocab[key]['src_his_query'] = []\n",
    "    user_vocab[key]['all_his'] = []\n",
    "    user_vocab[key]['all_his_ts'] = []\n",
    "    user_vocab[key]['all_his_query'] = []\n",
    "\n",
    "new_sar_inter_list = []\n",
    "for _, line in tqdm(sar_inter.iterrows()):\n",
    "    user_id, item_id, timestamp,\\\n",
    "        search_session_id, behavior = line['user_id'], line['item_id'], \\\n",
    "            line['timestamp'], line['search_session_id'], line['behavior']\n",
    "    \n",
    "    cur_rec_his_len = len(user_vocab[user_id]['rec_his'])\n",
    "    cur_src_session_his_len = len(user_vocab[user_id]['src_session_his'])\n",
    "    cur_src_his_len = len(user_vocab[user_id]['src_his'])\n",
    "    cur_all_his_len = len(user_vocab[user_id]['all_his'])\n",
    "    \n",
    "    new_sar_inter_list.append((user_id,item_id,timestamp, search_session_id,behavior,\\\n",
    "                               cur_rec_his_len,cur_src_session_his_len,cur_src_his_len,cur_all_his_len))\n",
    "\n",
    "    if behavior == 1:\n",
    "        user_vocab[user_id]['rec_his'].append(item_id)\n",
    "        user_vocab[user_id]['rec_his_ts'].append(timestamp)\n",
    "        user_vocab[user_id]['all_his'].append(item_id)\n",
    "        user_vocab[user_id]['all_his_ts'].append(timestamp)\n",
    "        user_vocab[user_id]['all_his_query'].append(0)\n",
    "    elif behavior == 2:\n",
    "        user_vocab[user_id]['src_session_his'].append(search_session_id)\n",
    "        user_vocab[user_id]['src_session_his_ts'].append(timestamp)\n",
    "\n",
    "        session_info = session_vocab[search_session_id]\n",
    "        cur_query = session_info['keyword']\n",
    "        cur_session_pos = session_info['pos_items']\n",
    "        cur_session_ts = session_info['time_list']\n",
    "        assert len(cur_session_pos) == len(cur_session_ts)\n",
    "        \n",
    "        user_vocab[user_id]['src_his'].extend(cur_session_pos)\n",
    "        user_vocab[user_id]['src_his_ts'].extend(cur_session_ts)\n",
    "        user_vocab[user_id]['src_his_query'].extend([cur_query]*len(cur_session_pos))\n",
    "\n",
    "        user_vocab[user_id]['all_his'].extend(cur_session_pos)\n",
    "        user_vocab[user_id]['all_his_ts'].extend([timestamp]*len(cur_session_pos))\n",
    "        user_vocab[user_id]['all_his_query'].extend([cur_query]*len(cur_session_pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sar_inter_df = pd.DataFrame(data=new_sar_inter_list,\n",
    "                                columns=sar_inter.columns.to_list()+['rec_his','src_session_his','src_his','all_his'])\n",
    "new_sar_inter_df.head()\n",
    "new_sar_inter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(item_vocab,open(f'{save_path}/vocab/item_vocab.pkl','wb'))\n",
    "\n",
    "pickle.dump(user_vocab,open(f'{save_path}/vocab/user_vocab.pkl','wb'))\n",
    "\n",
    "pickle.dump(session_vocab,open(f'{save_path}/vocab/src_session_vocab.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sar_inter_df[(new_sar_inter_df['rec_his'] == 0) & (new_sar_inter_df['src_his'] == 0)].shape\n",
    "\n",
    "new_sar_inter_df[(new_sar_inter_df['rec_his'] > 0) & (new_sar_inter_df['src_his'] > 0)].shape\n",
    "\n",
    "new_sar_inter_df[(new_sar_inter_df['rec_his'] > 0)].shape\n",
    "\n",
    "new_sar_inter_df[(new_sar_inter_df['src_his'] > 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sar_inter_df = new_sar_inter_df.sort_values(by=['timestamp']).reset_index(drop=True)\n",
    "new_sar_inter_df['rec_train'] = 0\n",
    "new_sar_inter_df['src_train'] = 0\n",
    "\n",
    "data_num = len(new_sar_inter_df)\n",
    "\n",
    "\n",
    "new_sar_inter_df['rec_train'] = 1\n",
    "\n",
    "new_sar_inter_df['src_train'] = 1\n",
    "\n",
    "new_sar_inter_df[new_sar_inter_df['behavior'] == 1]['rec_train'].value_counts()\n",
    "new_sar_inter_df[new_sar_inter_df['behavior'] == 2]['src_train'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(user_df):\n",
    "    user_df['train'].iloc[-1] = 3\n",
    "    user_df['train'].iloc[-2] = 2\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rec Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_inter.copy()\n",
    "rec_w_his_inter = rec_w_his_inter.sort_values(by=['user_id','timestamp']).reset_index(drop=True)\n",
    "rec_w_his_inter.shape\n",
    "rec_w_his_inter.head(1)\n",
    "\n",
    "rec_new_sar_inter_df = new_sar_inter_df[new_sar_inter_df.behavior==1].rename(columns={'rec_train':'train'})\n",
    "rec_new_sar_inter_df = rec_new_sar_inter_df.sort_values(by=['user_id','timestamp']).reset_index(drop=True)\n",
    "rec_new_sar_inter_df.shape\n",
    "rec_new_sar_inter_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter[['train','rec_his','src_session_his','src_his','all_his']] = rec_new_sar_inter_df[['train','rec_his','src_session_his','src_his','all_his']]\n",
    "rec_w_his_inter = rec_w_his_inter.reset_index(drop=True)\n",
    "rec_w_his_inter.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_w_his_inter[(rec_w_his_inter['rec_his'] > 0) | (rec_w_his_inter['src_session_his'] > 0)].reset_index(drop=True)\n",
    "rec_w_his_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter_num = rec_w_his_inter.groupby(by=['user_id']).count().reset_index()\n",
    "filtered_users_rec = rec_inter_num[rec_inter_num['item_id'] >= 3]\n",
    "filtered_users_rec.head(3), filtered_users_rec['item_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_users_rec['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_w_his_inter[rec_w_his_inter['user_id'].isin(set(filtered_users_rec['user_id'].unique()))]\n",
    "rec_w_his_inter = rec_w_his_inter.reset_index(drop=True)\n",
    "rec_w_his_inter.head()\n",
    "rec_w_his_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter_train = rec_w_his_inter.groupby('user_id').apply(splitTrainTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train = rec_w_his_inter_train[rec_w_his_inter_train.train==1].reset_index(drop=True)\n",
    "rec_train = rec_train.sort_values(by=['user_id', 'timestamp']).reset_index(drop=True)\n",
    "rec_train.drop(['train'],axis=1,inplace=True)\n",
    "rec_train.shape\n",
    "\n",
    "\n",
    "rec_val = rec_w_his_inter_train[rec_w_his_inter_train.train==2].reset_index(drop=True)\n",
    "rec_val = rec_val.sort_values(by=['user_id', 'timestamp']).reset_index(drop=True)\n",
    "rec_val.drop(['train'],axis=1,inplace=True)\n",
    "rec_val.shape\n",
    "\n",
    "rec_test = rec_w_his_inter_train[rec_w_his_inter_train.train==3].reset_index(drop=True)\n",
    "rec_test = rec_test.sort_values(by=['user_id', 'timestamp']).reset_index(drop=True)\n",
    "rec_test.drop(['train'],axis=1,inplace=True)\n",
    "rec_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train['user_id'].nunique()\n",
    "rec_val['user_id'].nunique()\n",
    "rec_test['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample negative for val and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_neg_samples = 4\n",
    "num_test_neg_samples = 99\n",
    "\n",
    "rec_item_set = rec_w_his_inter['item_id'].to_list()\n",
    "\n",
    "def SampleNegatives(row, cur_num_samples):\n",
    "    count = 0 \n",
    "    user_id = int(row['user_id'])\n",
    "    cur_pos = int(row['item_id'])\n",
    "    cur_all_his = user_vocab[user_id]['all_his'][:int(row['all_his'])]\n",
    "\n",
    "    neg_samples = []\n",
    "    while count < cur_num_samples:\n",
    "        cur_neg = random.choice(rec_item_set)\n",
    "        if (cur_neg in cur_all_his) or (cur_neg in neg_samples) or (cur_neg == cur_pos):\n",
    "            continue\n",
    "        count += 1\n",
    "        neg_samples.append(cur_neg)\n",
    "    return neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train['neg_items'] = rec_train.parallel_apply(SampleNegatives,cur_num_samples=4,axis=1)\n",
    "rec_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_val['neg_items'] = rec_val.parallel_apply(SampleNegatives,cur_num_samples=99,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_test['neg_items'] = rec_test.parallel_apply(SampleNegatives,cur_num_samples=99,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train.to_pickle(f'{save_path}/dataset/rec_train.pkl')\n",
    "\n",
    "rec_val.to_pickle(f'{save_path}/dataset/rec_val.pkl')\n",
    "\n",
    "rec_test.to_pickle(f'{save_path}/dataset/rec_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JOINT_SAR",
   "language": "python",
   "name": "joint_sar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
