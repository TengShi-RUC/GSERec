{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import html\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "\n",
    "setup_seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = pd.read_pickle(f\"{base_path}/raw_data/item_info.pkl\")\n",
    "item_features.head()\n",
    "item_features.shape\n",
    "\n",
    "item_vocab = item_features.set_index('item_id',drop=False).to_dict('index')\n",
    "item_vocab[1]\n",
    "\n",
    "item_features['item_id'].nunique()\n",
    "item_features['item_id'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Build BM25 index -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features.head()\n",
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_text(row):\n",
    "    return ' '.join([row['title'], row['description']])\n",
    "    \n",
    "\n",
    "item_features['text'] = item_features.parallel_apply(get_item_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_null_text(row):\n",
    "    row_text = row['text'].strip()\n",
    "    return len(row_text)==0\n",
    "\n",
    "item_df_null_text = item_features.apply(count_null_text,axis=1)\n",
    "item_df_null_text\n",
    "item_df_null_text.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_index = item_features[['item_id','text']].rename(columns={'item_id':'id', 'text':'contents'})\n",
    "item_index = item_index.astype({'id':'str', 'contents':'str'})\n",
    "item_index.head()\n",
    "item_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vocab[14885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vocab = pickle.load(open('../vocab/query_vocab.pkl', 'rb'))\n",
    "len(query_vocab)\n",
    "query_vocab[1]['query']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = pd.read_pickle(f\"{base_path}/raw_data/user_profile.pkl\")\n",
    "user_features.head()\n",
    "\n",
    "user_vocab = user_features.set_index('user_id',drop=False).to_dict('index')\n",
    "user_vocab[0]\n",
    "\n",
    "user_features['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter = pd.read_pickle(f\"{base_path}/raw_data/rec_inter.pkl\")\n",
    "rec_inter.head()\n",
    "rec_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_inter = pd.read_pickle(f\"{base_path}/raw_data/src_inter.pkl\")\n",
    "src_inter.head()\n",
    "src_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info = pd.read_pickle(f\"{base_path}/raw_data/session_info.pkl\")\n",
    "session_info.head()\n",
    "session_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_vocab = session_info.set_index('search_session_id',drop=False).to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_item_set = set(rec_inter['item_id'].unique())\n",
    "src_item_set = set(src_inter['item_id'].unique())\n",
    "\n",
    "len(rec_item_set)\n",
    "len(src_item_set)\n",
    "len(rec_item_set | src_item_set)\n",
    "len(rec_item_set & src_item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_user_set = set(rec_inter['user_id'].unique())\n",
    "src_user_set = set(src_inter['user_id'].unique())\n",
    "\n",
    "len(rec_user_set)\n",
    "len(src_user_set)\n",
    "len(rec_user_set | src_user_set)\n",
    "len(rec_user_set & src_user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_rec_inter = rec_inter[['user_id','item_id','ts','score']].copy()\n",
    "sub_rec_inter['search_session_id'] = 'nan'\n",
    "sub_rec_inter['behavior'] = 1\n",
    "\n",
    "sub_session_src_inter = src_inter[['user_id','ts','search_session_id']].copy()\n",
    "sub_session_src_inter['item_id'] = 'nan'\n",
    "sub_session_src_inter['behavior'] = 2\n",
    "sub_session_src_inter['score'] = 10000\n",
    "\n",
    "sar_inter = pd.concat([sub_rec_inter,sub_session_src_inter],axis=0)\n",
    "sar_inter = sar_inter.sort_values(by=['user_id','ts','score']).reset_index(drop=True)\n",
    "sar_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_vocab = {}\n",
    "for key in rec_inter['user_id'].unique():\n",
    "    # user_vocab[key] = {}\n",
    "\n",
    "    user_vocab[key]['rec_his'] = []\n",
    "    user_vocab[key]['rec_his_ts'] = []\n",
    "    user_vocab[key]['src_session_his'] = []\n",
    "    user_vocab[key]['src_session_his_ts'] = []\n",
    "    user_vocab[key]['src_his'] = []\n",
    "    user_vocab[key]['src_his_ts'] = []\n",
    "    user_vocab[key]['src_his_query'] = []\n",
    "    user_vocab[key]['all_his'] = []\n",
    "    user_vocab[key]['all_his_ts'] = []\n",
    "    user_vocab[key]['all_his_query'] = []\n",
    "\n",
    "new_sar_inter_list = []\n",
    "for _, line in tqdm(sar_inter.iterrows()):\n",
    "    user_id, item_id, timestamp,\\\n",
    "        search_session_id, behavior = line['user_id'], line['item_id'], \\\n",
    "            line['ts'], line['search_session_id'], line['behavior']\n",
    "    \n",
    "    cur_rec_his_len = len(user_vocab[user_id]['rec_his'])\n",
    "    cur_src_session_his_len = len(user_vocab[user_id]['src_session_his'])\n",
    "    cur_src_his_len = len(user_vocab[user_id]['src_his'])\n",
    "    cur_all_his_len = len(user_vocab[user_id]['all_his'])\n",
    "\n",
    "    if behavior == 2:\n",
    "        if session_vocab[search_session_id]['pos_items'][0] == user_vocab[user_id]['rec_his'][-1]:\n",
    "            cur_rec_his_len -= 1\n",
    "    \n",
    "    new_sar_inter_list.append((user_id,item_id,timestamp, search_session_id,behavior,\\\n",
    "                               cur_rec_his_len,cur_src_session_his_len,cur_src_his_len,cur_all_his_len))\n",
    "\n",
    "    if behavior == 1:\n",
    "        user_vocab[user_id]['rec_his'].append(item_id)\n",
    "        user_vocab[user_id]['rec_his_ts'].append(timestamp)\n",
    "        user_vocab[user_id]['all_his'].append(item_id)\n",
    "        user_vocab[user_id]['all_his_ts'].append(timestamp)\n",
    "        user_vocab[user_id]['all_his_query'].append(0)\n",
    "    elif behavior == 2:\n",
    "        user_vocab[user_id]['src_session_his'].append(search_session_id)\n",
    "        user_vocab[user_id]['src_session_his_ts'].append(timestamp)\n",
    "\n",
    "        cur_query = session_vocab[search_session_id]['keyword']\n",
    "\n",
    "        cur_session_pos = session_vocab[search_session_id]['pos_items']\n",
    "        user_vocab[user_id]['src_his'].extend(cur_session_pos)\n",
    "        user_vocab[user_id]['src_his_ts'].extend([timestamp]*len(cur_session_pos))\n",
    "        user_vocab[user_id]['src_his_query'].extend([cur_query]*len(cur_session_pos))\n",
    "\n",
    "        user_vocab[user_id]['all_his'].extend(cur_session_pos)\n",
    "        user_vocab[user_id]['all_his_ts'].extend([timestamp]*len(cur_session_pos))\n",
    "        user_vocab[user_id]['all_his_query'].extend([cur_query]*len(cur_session_pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sar_inter_df = pd.DataFrame(data=new_sar_inter_list,\n",
    "                                columns=['user_id','item_id','ts','search_session_id','behavior',\n",
    "                                         'rec_his','src_session_his','src_his','all_his'])\n",
    "new_sar_inter_df.head()\n",
    "new_sar_inter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(item_vocab,open(f\"{base_path}/vocab/item_vocab.pkl\",'wb'))\n",
    "\n",
    "pickle.dump(user_vocab,open(f\"{base_path}/vocab/user_vocab.pkl\",'wb'))\n",
    "\n",
    "pickle.dump(session_vocab,open(f\"{base_path}/vocab/src_session_vocab.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTest(user_df):\n",
    "    user_df['train'].iloc[-1] = 3\n",
    "    user_df['train'].iloc[-2] = 2\n",
    "    return user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rec Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_inter.copy()\n",
    "rec_w_his_inter = rec_w_his_inter.sort_values(by=['user_id','ts']).reset_index(drop=True)\n",
    "rec_w_his_inter.shape\n",
    "rec_w_his_inter.head(1)\n",
    "\n",
    "rec_new_sar_inter_df = new_sar_inter_df[new_sar_inter_df.behavior==1]\n",
    "rec_new_sar_inter_df = rec_new_sar_inter_df.sort_values(by=['user_id','ts']).reset_index(drop=True)\n",
    "rec_new_sar_inter_df.shape\n",
    "rec_new_sar_inter_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter[['rec_his','src_session_his',\n",
    "                 'src_his','all_his']] = rec_new_sar_inter_df[['rec_his','src_session_his','src_his','all_his']]\n",
    "rec_w_his_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_w_his_inter[(rec_w_his_inter['rec_his']!=0) & (rec_w_his_inter['src_session_his']!=0)]\n",
    "rec_w_his_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_inter_num = rec_w_his_inter.groupby(by=['user_id']).count().reset_index()\n",
    "filtered_users_rec = rec_inter_num[rec_inter_num['item_id'] >= 3]\n",
    "filtered_users_rec.head(3), filtered_users_rec['item_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_w_his_inter = rec_w_his_inter[rec_w_his_inter['user_id'].isin(set(filtered_users_rec['user_id'].unique()))]\n",
    "rec_w_his_inter = rec_w_his_inter.reset_index(drop=True)\n",
    "rec_w_his_inter.head()\n",
    "rec_w_his_inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_w_his_inter['train'] = 1\n",
    "rec_w_his_inter_train = rec_w_his_inter.groupby('user_id').apply(splitTrainTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train = rec_w_his_inter_train[rec_w_his_inter_train.train==1].reset_index(drop=True)\n",
    "rec_train.drop(['train'],axis=1,inplace=True)\n",
    "rec_train.shape\n",
    "\n",
    "rec_val = rec_w_his_inter_train[rec_w_his_inter_train.train==2].reset_index(drop=True)\n",
    "rec_val.drop(['train'],axis=1,inplace=True)\n",
    "rec_val.shape\n",
    "\n",
    "rec_test = rec_w_his_inter_train[rec_w_his_inter_train.train==3].reset_index(drop=True)\n",
    "rec_test.drop(['train'],axis=1,inplace=True)\n",
    "rec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sample negative for val and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_neg_samples = 4\n",
    "num_test_neg_samples = 99\n",
    "\n",
    "item_set = rec_w_his_inter['item_id'].to_list()\n",
    "\n",
    "def SampleNegatives(row, cur_num_samples):\n",
    "    count = 0 \n",
    "    user_id = int(row['user_id'])\n",
    "    cur_pos = int(row['item_id'])\n",
    "    cur_all_his = user_vocab[user_id]['all_his'][:int(row['all_his'])]\n",
    "\n",
    "\n",
    "    neg_samples = []\n",
    "    while count < cur_num_samples:\n",
    "        cur_neg = random.choice(item_set)\n",
    "        if (cur_neg in cur_all_his) or (cur_neg in neg_samples) or (cur_neg == cur_pos):\n",
    "            continue\n",
    "        count += 1\n",
    "        neg_samples.append(cur_neg)\n",
    "    return neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train['neg_items'] = rec_train.parallel_apply(SampleNegatives,cur_num_samples=4,axis=1)\n",
    "rec_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_val['neg_items'] = rec_val.parallel_apply(SampleNegatives,cur_num_samples=99,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_test['neg_items'] = rec_test.parallel_apply(SampleNegatives,cur_num_samples=99,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_train.to_pickle(f\"{base_path}/dataset/rec_train.pkl\")\n",
    "\n",
    "rec_val.to_pickle(f\"{base_path}/dataset/rec_val.pkl\")\n",
    "\n",
    "rec_test.to_pickle(f\"{base_path}/dataset/rec_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JOINT_SAR",
   "language": "python",
   "name": "joint_sar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
